{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013892bb-9e6d-40ab-b527-edc694e1d944",
   "metadata": {},
   "source": [
    "<h4>Gemini API Setup</h4>\n",
    "<p>To compare product suggestions from Bing and ChatGPT, we extract the relevant products either from ChatGPT’s response text or directly from Bing’s search result page, leveraging the Gemini API for efficient processing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc04da4b-5b3a-4f31-b9da-7c82b60a81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576f6a9-c185-4427-9137-64eb8911bfcc",
   "metadata": {},
   "source": [
    "<p>We use the Gemini 2.5 Pro model to extract recommended products from large text sources because it provides advanced natural language understanding and efficient context handling. The model can process long passages, identify relevant entities, and infer relationships between products and user preferences within a single request. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c1e555-362f-49ac-a466-a4846edee63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini Setupt\n",
    "load_dotenv()\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client()\n",
    "\n",
    "# Model\n",
    "gemini_model = \"gemini-2.5-pro\"\n",
    "\n",
    "# Behavior\n",
    "with open(\"gemini_behavior.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gemini_behavior = f.read().strip()\n",
    "\n",
    "# Rate Limit per Minute\n",
    "gemini_rpm = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9cd927-b16d-4fd8-8b0b-6d5409cfd66e",
   "metadata": {},
   "source": [
    "<p>\n",
    "We configure the Gemini 2.5 Pro model to return the extracted recommended products as a JSON list object.  \n",
    "This ensures the output is structured, machine-readable, and easy to parse for downstream processing.  \n",
    "Additionally, the model is instructed to preserve the order in which products are mentioned in the text, allowing us to maintain the original sequence of recommendations and capture the natural flow of context or preference.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45562527-7f71-425c-b68f-90fc444230f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommended_products(product_text: str) -> list[str]:\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model = gemini_model,\n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction = gemini_behavior,\n",
    "                temperature = 0,\n",
    "                response_mime_type = \"application/json\",  # Force jsoon output\n",
    "                response_schema = {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"products\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\"type\": \"string\"}\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"products\"]\n",
    "                }\n",
    "            ),\n",
    "            contents = product_text\n",
    "        )\n",
    "        \n",
    "        # parse json response\n",
    "        result = json.loads(response.text)\n",
    "        return result.get(\"products\", [])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c03f90f-39ba-4135-bd6a-5f1ffc79780c",
   "metadata": {},
   "source": [
    "<h4>Recommended Products Extraction</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eaa9872-12a3-4a89-beee-7a56b0fab4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d9dfca8-bd65-4b04-a41f-814a259bd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_chatgpt_path = \"../../data/ChatGPT data/raw/chatgpt_chrome_ext.xlsx\"\n",
    "raw_bing_path = \"../../data/Bing data/raw/bing_chrome_ext.xlsx\"\n",
    "\n",
    "chatgpt_df = pd.read_excel(raw_chatgpt_path).dropna(how = \"all\").reset_index(drop = True)\n",
    "bing_df = pd.read_excel(raw_bing_path).dropna(how = \"all\").reset_index(drop = True)\n",
    "\n",
    "chatgpt_df[\"recommended_products\"], bing_df[\"recommended_products\"] = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37b4fbb-9b86-405b-b49d-e05009e4d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_recommended_products(df: pd.DataFrame, text_col: str, save_path: str) -> pd.DataFrame:\n",
    "    delay_per_call = 60.0 / gemini_rpm * 2\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        print(f\"Processing row {idx + 1} / {len(df)}\")\n",
    "\n",
    "        if pd.isna(row[text_col]) or row[text_col] == \"\":\n",
    "            print(f\"Skipping empty row {idx}...\")\n",
    "            continue\n",
    "        \n",
    "        df.at[idx, \"recommended_products\"] = get_recommended_products(row[text_col])\n",
    "        df.to_csv(save_path, index = False)\n",
    "\n",
    "        # rate limiting delay\n",
    "        time.sleep(delay_per_call)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe034c9-8cbc-4475-aac2-a2e806958c26",
   "metadata": {},
   "source": [
    "<h4>ChatGPT</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1052ba3-77d5-45ad-8994-07fbc1d710b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['market_type', 'product', 'query_level', 'query_index', 'run_number',\n",
       "       'query', 'response_text', 'web_search_forced', 'sources_cited',\n",
       "       'sources_additional', 'recommended_products'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e93997-ef45-4237-a069-87b7693d9f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT\n",
    "# modified_chatgpt_path = \"../../data/ChatGPT data/modified/chatgpt.xlsx\n",
    "# chatgpt_df = extract_recommended_products(df = chatgpt_df, text_col = \"response_text\", safe_path = modified_chatgpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4356ade2-7844-47b2-8852-d4ae025c1982",
   "metadata": {},
   "source": [
    "<h4>Bing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa471146-c285-44fb-82cc-26ce61e83dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['market_type', 'product', 'query_level', 'query', 'position', 'page',\n",
       "       'title', 'url', 'domain', 'display_url', 'snippet', 'content',\n",
       "       'content_length', 'content_error', 'manual_content_inspection',\n",
       "       'recommended_products'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bing_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a98d40b-d935-4c40-a281-cd6238b6e9c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bing\n",
    "# modified_bing_path = \"../../data/Bing data/modified/bing.xlsx\"\n",
    "# bing_df = extract_recommended_products(df = bing_df, text_col = \"content\", save_path = modified_bing_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
